{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Projet issu des données suivantes :\n",
        "\n",
        "# https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "xLJCz3SqeuYJ"
      },
      "outputs": [],
      "source": [
        "# Importation des library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "St89yccggMMw",
        "outputId": "f35d98b3-0d5e-4739-aada-aec7cb598635"
      },
      "outputs": [],
      "source": [
        "# Import et traitement des données\n",
        "def imp_clean (chemin_fic,sepa) :\n",
        "    df_train = pd.read_csv(chemin_fic, sep = sepa)\n",
        "    # Obtenir les noms des variables\n",
        "    noms_variables = df_train.columns\n",
        "    # modification des noms des variables\n",
        "    df_train = df_train.rename(columns={'battery_power': 'puissance_batterie', \n",
        "                         'blue': 'Bluetooth', \n",
        "                         'clock_speed': 'vitesse_micro_pross', \n",
        "                         'fc': 'nb_pixels_camera_front', \n",
        "                         'four_g': '4G', \n",
        "                         'int_memory': 'mémoire_interne',\n",
        "                         'm_dep': 'profondeur_tel',\n",
        "                         'mobile_wt': 'poids_tel',\n",
        "                         'n_cores': 'nb_coeurs',\n",
        "                         'pc': 'nb_pixels_camera_externe',\n",
        "                         'px_height': 'pixels_resolution_hauteur',\n",
        "                         'px_width': 'pixels_resolution_largeur',\n",
        "                         'sc_h': 'hauteur_tel',\n",
        "                         'sc_w': 'largeur_tel',\n",
        "                         'talk_time': 'duree_batterie_appel',\n",
        "                         'three_g': '3G',\n",
        "                         'touch_screen': 'ecran_tactile'})\n",
        "        # Remplacer les modalités dans la colonne\n",
        "    nouveaux_noms_modalites = {0: 'bas de gamme', 1: 'prix moyen', 2: 'prix élevé', 3: 'haut de gamme'}\n",
        "    df_train['price_range'] = df_train['price_range'].replace(nouveaux_noms_modalites)\n",
        "    return df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preparation_pour_model(df_train) :\n",
        "    # On sépare la variable à expliquer des variables explicatives\n",
        "    X = df_train.drop(\"price_range\",axis=1)\n",
        "    y = df_train['price_range']\n",
        "    # On split le train et le test à 80 % et 20 %\n",
        "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "    # On prévoit d'utiliser le scaler pour centrer et réduire les variables quantitatives\n",
        "    scaler = StandardScaler()\n",
        "    # On applique le scaler à nos échantillons\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "def modelisation():\n",
        "    # Application de la regression logistique sur notre échantillon d'apprentissage\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train,y_train)\n",
        "    model.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluation_model() :\n",
        "    # Création de la pipeline\n",
        "    pLg = make_pipeline(StandardScaler(),\n",
        "                        LogisticRegression())\n",
        "    pLg.fit(X_train, y_train)\n",
        "    print(pLg.score(X_train, y_train), pLg.score(X_test, y_test))\n",
        "    y_pred = pLg.predict(X_test)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Convertir la matrice de confusion en pourcentage\n",
        "    conf_matrix_percent = conf_matrix / conf_matrix.sum(axis=1, keepdims=True) * 100\n",
        "\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "    print(f\"L'accuracy est de : ------>>  {accuracy_score(y_test, y_pred)}\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "    print(f\"La matrice de confusion (%) est la suivante : ------>> \\n{conf_matrix_percent}\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "    print(f\"Tableau récapitulatif : ---->> {classification_report(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roc():\n",
        "    # Création de la courbe de ROC\n",
        "\n",
        "    # Générer des données de démonstration\n",
        "    X, y = make_classification(n_samples=1000, n_classes=4, n_clusters_per_class=1, random_state=0)\n",
        "\n",
        "    # Binariser les étiquettes (dummies)\n",
        "    y_bin = label_binarize(y, classes=[0, 1, 2, 3])\n",
        "\n",
        "    # Diviser les données en ensemble d'entraînement et ensemble de test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Utiliser OneVsRestClassifier avec un classificateur binaire (par exemple, Logistic Regression)\n",
        "    classifier = OneVsRestClassifier(LogisticRegression())\n",
        "\n",
        "    # On applique le scaler à nos échantillons\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Ajuster le modèle\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Obtenir les scores des probabilités\n",
        "    y_score = classifier.predict_proba(X_test)\n",
        "\n",
        "    # Calculer les courbes ROC et les aires sous la courbe pour chaque classe\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(4):  # 4 classes dans cet exemple\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Tracer les courbes ROC\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(4):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'{nouveaux_noms_modalites[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('Taux de faux positif')\n",
        "    plt.ylabel('Taux de vrai positif')\n",
        "    plt.title('Courbes ROC des différentes classes de prix')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(chemin,separ,df_train) :\n",
        "    imp_clean(chemin,separ)\n",
        "    preparation_pour_model(df_train)\n",
        "    modelisation()\n",
        "    evaluation_model()\n",
        "    roc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main(\u001b[39m'\u001b[39m\u001b[39mtrain.csv\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,df_train)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ],
      "source": [
        "main('train.csv',',',df_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
